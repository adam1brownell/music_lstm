{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras==2.1.1 in /anaconda3/lib/python3.6/site-packages (2.1.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /anaconda3/lib/python3.6/site-packages (from keras==2.1.1) (1.1.0)\n",
      "Requirement already satisfied: pyyaml in /anaconda3/lib/python3.6/site-packages (from keras==2.1.1) (3.12)\n",
      "Requirement already satisfied: six>=1.9.0 in /anaconda3/lib/python3.6/site-packages (from keras==2.1.1) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /anaconda3/lib/python3.6/site-packages (from keras==2.1.1) (1.14.3)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==1.4.0 in /anaconda3/lib/python3.6/site-packages (1.4.0)\n",
      "Requirement already satisfied: numpy>=1.12.1 in /anaconda3/lib/python3.6/site-packages (from tensorflow==1.4.0) (1.14.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /anaconda3/lib/python3.6/site-packages (from tensorflow==1.4.0) (1.11.0)\n",
      "Requirement already satisfied: tensorflow-tensorboard<0.5.0,>=0.4.0rc1 in /anaconda3/lib/python3.6/site-packages (from tensorflow==1.4.0) (0.4.0)\n",
      "Requirement already satisfied: enum34>=1.1.6 in /anaconda3/lib/python3.6/site-packages (from tensorflow==1.4.0) (1.1.6)\n",
      "Requirement already satisfied: protobuf>=3.3.0 in /anaconda3/lib/python3.6/site-packages (from tensorflow==1.4.0) (3.6.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /anaconda3/lib/python3.6/site-packages (from tensorflow==1.4.0) (0.31.1)\n",
      "Requirement already satisfied: html5lib==0.9999999 in /anaconda3/lib/python3.6/site-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.0) (0.9999999)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /anaconda3/lib/python3.6/site-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.0) (3.0.1)\n",
      "Requirement already satisfied: bleach==1.5.0 in /anaconda3/lib/python3.6/site-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.0) (1.5.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /anaconda3/lib/python3.6/site-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.0) (0.14.1)\n",
      "Requirement already satisfied: setuptools in /anaconda3/lib/python3.6/site-packages (from protobuf>=3.3.0->tensorflow==1.4.0) (39.1.0)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upcoming Modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training Change: Add Rests as notes\n",
    "# for element in notes_to_parse:\n",
    "#     if isinstance(element, note.Note):\n",
    "#         notes.append(str(element.pitch))\n",
    " \n",
    "#     elif isinstance(element,chord.Chord):\n",
    "#         notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "        \n",
    "#     elif isinstance(element,note.Rest):\n",
    "#         notes.append(str('R'))\n",
    "# # # Training Change: Add Start/End Markers\n",
    "\n",
    "# # # Append the pitch of every note\n",
    "# # notes.append('start')\n",
    "# # for element in notes_to_parse:\n",
    "# #     ...\n",
    "# #     #stuff\n",
    "# # notes.append('end')\n",
    "\n",
    "# # Feature Add: Duration\n",
    "# note = notes_to_parse[7]\n",
    "# print('Note Length:', note.duration.type)\n",
    "# rest = notes_to_parse[6]\n",
    "# print('Rest Length:', rest.duration.type)\n",
    "\n",
    "# # Feature Add: Offset Change\n",
    "# # Is this a feature? Or is this inherent to duration (i.e I can just add this appropriately afterwards?)\n",
    "# # ANSWER: Doesn't look like it\n",
    "# last_offset = 0\n",
    "# offsets = []\n",
    "# for element in notes_to_parse:\n",
    "#     if isinstance(element, note.Note):\n",
    "#         notes.append(str(element.pitch))\n",
    " \n",
    "#     elif isinstance(element,chord.Chord):\n",
    "#         notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "        \n",
    "#     elif isinstance(element,note.Rest):\n",
    "#         notes.append(str('R'))\n",
    "    \n",
    "#     offset_delta = element.offset - last_offset\n",
    "#     if offset_delta < 0:\n",
    "#         print(offset_delta)\n",
    "#         break\n",
    "#     offsets.append(offset_delta)\n",
    "#     last_offset = element.offset\n",
    "\n",
    "# ... \n",
    "# x = note.Note('A3')\n",
    "# x.offset = 0.5\n",
    "\n",
    "# from collections import Counter\n",
    "# Counter(offsets)\n",
    "\n",
    "# # Model Change: Stateful\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start 🏄 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "pkg_resources.require('tensorflow==1.4.0')\n",
    "pkg_resources.require('keras==2.1.1')\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "from keras.utils import to_categorical\n",
    "from keras import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, Activation\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156 guitar songs\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for file in glob.glob(\"midi_songs_guitar/*.mid\"):\n",
    "    i += 1\n",
    "print(i,'guitar songs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting: cm_cafe_de_chintas\n",
      "Converting: pdl_serrana_de_malaga\n",
      "Converting: pp_riomar_(fandangos)\n",
      "Converting: pdl_chick\n",
      "Converting: fgl_tarara  || failed to parse\n",
      "Converting: trad_sevil1  || failed to parse\n",
      "Converting: trad_farruca  || failed to parse\n",
      "Converting: trad_sevil3  || failed to parse\n",
      "Converting: pp_santuario_(soleares)\n",
      "Converting: tom_alegria  || failed to parse\n",
      "Converting: fgl_boyso  || failed to parse\n",
      "Converting: Sabicas_Columbiana\n",
      "Converting: sab_aires_de_triana_(buleria)\n",
      "Converting: sab_castellana\n",
      "Converting: pdl_a_tu_vera\n",
      "Converting: gn_bulerias\n",
      "Converting: trad_sevil2  || failed to parse\n",
      "Converting: pp_colombiana\n",
      "Converting: pdl_entre_dos_aguas1\n",
      "Converting: pdl_plazuela_(buleria)\n",
      "Converting: pp_bulerias_cortas\n",
      "Converting: pdl_plaza_alta_(2)\n",
      "Converting: pdl_celosa_(solea)1\n",
      "Converting: pdl_mi_inspiration\n",
      "Converting: pdl_farruca\n",
      "Converting: sab_fantasia_inca  || failed to parse\n",
      "Converting: pp_la_isla_(alegria)  || failed to parse\n",
      "Converting: pp_la_lola_(rumba)  || failed to parse\n",
      "Converting: pdl_mediterranean_sundance\n",
      "Converting: pdl_gloria_al_nino_ricardo\n",
      "Converting: pdl_llanos_de_real\n",
      "Converting: pdl_entre_dos_aguas2\n",
      "Converting: trad_las_cintas_de_mi_capa\n",
      "Converting: ser_solea\n",
      "Converting: as_solea\n",
      "Converting: pdl_celosa_(solea)2\n",
      "Converting: sab_embrujo_sevillano_(buleria)\n",
      "Converting: fgl_zorongo  || failed to parse\n",
      "Converting: gr_jota_flamenca\n",
      "Converting: trad_guajira  || failed to parse\n",
      "Converting: trad_sevil4\n",
      "Converting: pp_cancion_(petenera)  || failed to parse\n",
      "Converting: eds_mantilla_de_feria  || failed to parse\n",
      "Converting: pdl_guardian_angel\n",
      "Converting: sab_fandangos\n",
      "Converting: pp_santuario_(soleares)2\n",
      "Converting: pp_garrotin\n",
      "Converting: sab_bronce_gitano_(solea)\n",
      "Converting: pdl_el_tempul_(fandangos)2\n",
      "Converting: gr_aires_colombianas\n",
      "Converting: pdl_umbria\n",
      "Converting: eds_panaderos1\n",
      "Converting: trad_guajira_y_buleria\n",
      "Converting: pdl_sevillanas_populaires_(2)\n",
      "Converting: tom_soledad_(solea)\n",
      "Converting: eds_panaderos3\n",
      "Converting: pp_la_romeria_(alegria)\n",
      "Converting: trad_mi_favorita\n",
      "Converting: sab_delicada\n",
      "Converting: pdl_zarda_de_monty\n",
      "Converting: Paco_de_Lucia_Entre_dos_Aguas\n",
      "Converting: trad_alzapua_falsetas\n",
      "Converting: rr_nino_miguel\n",
      "Converting: pdl_el_tempul_(fandangos)1  || failed to parse\n",
      "Converting: rm_soleares\n",
      "Converting: eds_panaderos2\n",
      "Converting: Paco_de_Lucia_Guajiras_Lucia\n",
      "Converting: pdl_los_pinares\n",
      "Converting: pdl_recuerdo_a_patino\n",
      "Converting: trad_serranas\n",
      "Converting: pp_los_veleros\n",
      "Converting: fgl_el_vito\n",
      "Converting: pp_medina_azahara\n",
      "Converting: pdl_cuando_canta_el_gallo_(solea)1  || failed to parse\n",
      "Converting: fgl_cuatro_muleros  || failed to parse\n",
      "Converting: trad_anosolea_(solea)\n",
      "Converting: Sabicas_Farruca\n",
      "Converting: eds_panaderos5\n",
      "Converting: sab_temas_gitanos_(buleria)  || failed to parse\n",
      "Converting: trad_caracoles  || failed to parse\n",
      "Converting: gr_ole_andalucia\n",
      "Converting: sab_siguiriyas\n",
      "Converting: pdl_cuando_canta_el_gallo_(solea)2\n",
      "Converting: sab_rumba\n",
      "Converting: trad_rumba\n",
      "Converting: pdl_monasterio_de_sal\n",
      "Converting: eds_panaderos4\n",
      "Converting: pdl_fuente_y_caudal\n",
      "Converting: pdl_percusion_flamenca_(zapateado)\n",
      "Converting: pdl_frevo_rasgado\n",
      "Converting: fgl_el_cafe_de_chinitas  || failed to parse\n",
      "Converting: ps_lagunas_de_sal\n",
      "Converting: pdl_plaza_de_san_juan_(alegrias)\n",
      "Converting: pp_rumbeando_la_milonga\n",
      "Converting: pdl_solea_falsetas  || failed to parse\n",
      "Converting: trad_malaguena  || failed to parse\n",
      "Converting: pdl_taranta_tremolo  || failed to parse\n",
      "Converting: trad_fandanguillo\n",
      "Converting: sab_zambra\n",
      "Converting: pdl_plaza_de_san_juan2\n",
      "Converting: pp_herencia_latina_(rumba)  || failed to parse\n",
      "Converting: trad_espana_cani  || failed to parse\n",
      "Converting: Lucia_Rio_Ancho\n",
      "Converting: sab_taranto  || failed to parse\n",
      "Converting: trad_milonga  || failed to parse\n",
      "Converting: pdl_taconeo_gitano\n",
      "Converting: pdl_aires_choqueros_(fandangos)\n",
      "Converting: Paco_de_Lucia_Punta_Umbria\n",
      "Converting: pp_herencia_latina_(rumba)2\n",
      "Converting: pdl_cueva_del_gato  || failed to parse\n",
      "Converting: pdl_passion_grace_and_fire\n",
      "Converting: trad_rubia\n",
      "Converting: pdl_rio_ancho_(rumba)\n",
      "Converting: Sabicas_Fantasia_Inca\n",
      "Converting: Sabicas_Bulerias\n",
      "Converting: pm_zambra\n",
      "Converting: sab_punta_y_tacon\n",
      "Converting: sab_campina_andaluza  || failed to parse\n",
      "Converting: ps_soleares\n",
      "Converting: pdl_sevillanas_populaires_(1)\n",
      "Converting: Sabicas_Castellana\n",
      "Converting: Sabicas_Delicada\n",
      "Converting: sab_fantasia_arabe\n",
      "Converting: Sabicas_Alegrias\n",
      "Converting: pp_el_cafe_de_chinitas  || failed to parse\n",
      "Converting: pdl_el_inclusero_(rumba)\n",
      "Converting: trad_espana_cani-2\n",
      "Converting: trad_rubia2\n",
      "Converting: Paco_de_Lucia_Los_Pinares\n",
      "Converting: Sabicas_Fantasia_Arabe\n",
      "Converting: sab_costa_brava  || failed to parse\n",
      "Converting: Sabicas_Fandangos\n",
      "Converting: pp_a_paso_lento_(tientos)\n",
      "Converting: pp_la_lola2\n",
      "Converting: pdl_plaza_alta_(1)\n",
      "Converting: pdl_almoraima\n",
      "Converting: pp_acera_ael_rio_(soleares)\n",
      "Converting: pdl_malaguena_de_lecuona\n",
      "Converting: ser_fandangos\n",
      "Converting: pdl_mediterranean_sundance2\n",
      "Converting: pp_tangos\n",
      "Converting: pdl_cepa_andaluza\n",
      "Converting: pdl_aires_choqueros_(fandangos)2\n",
      "Converting: Paco_de_Lucia_Tempul\n",
      "Converting: pp_bulerias  || failed to parse\n",
      "Converting: pdl_entre_arrayanes\n",
      "Converting: trad_fandangos_carmona  || failed to parse\n",
      "Converting: Paco_de_Lucia_Sortilegio\n",
      "Converting: pp_taranto\n",
      "Converting: pdl_guajiras_de_lucia  || failed to parse\n",
      "Converting: Sabicas_Taranto\n",
      "Converting: pdl_sortilegio  || failed to parse\n",
      "Converting: trad_colombianas_compas\n",
      "Converting: trad_malaguena2  || failed to parse\n",
      "Converting: ser_guajiras\n",
      "Converting: ph_buleria\n",
      "76.92 % of songs converted successfully\n"
     ]
    }
   ],
   "source": [
    "notes = []\n",
    "durations = []\n",
    "pp = 0\n",
    "for file in glob.glob(\"midi_songs_guitar/*.mid\"):\n",
    "    txt = 'Converting: '+file[len('midi_songs_guitar/'):-len('.mid')]\n",
    "    try:\n",
    "        midi = converter.parse(file)\n",
    "        print(txt)\n",
    "    except:\n",
    "        print(txt,' || failed to parse')\n",
    "        continue\n",
    "        \n",
    "    notes_to_parse = None\n",
    "    \n",
    "    parts = instrument.partitionByInstrument(midi)\n",
    "    \n",
    "    if parts: # file has instrument parts\n",
    "        notes_to_parse = parts.parts[0].recurse()\n",
    "    else:\n",
    "        notes_to_parse = midi.flat.notes\n",
    "        \n",
    "    # Append the pitch and duration of every note\n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note) or isinstance(element,chord.Chord) or isinstance(element,note.Rest):\n",
    "            \n",
    "            # music21 can't handle notes beyond a certain speed. This skips them\n",
    "            # In the original run, there was only 1 note in 2 files that broke it\n",
    "            try:\n",
    "                note_length = element.duration.type\n",
    "            except: # This is naked because the except raised by music21 is custom \n",
    "                print(file)\n",
    "                continue\n",
    "            \n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            # If chord, encode ID of every note in cord separated by .\n",
    "            elif isinstance(element,chord.Chord):\n",
    "                chord_notes = [str(n) for n in element.pitches]\n",
    "                notes.append(chord_notes)\n",
    "            elif isinstance(element,note.Rest):\n",
    "                # Sorry, I'm going to clear out 16th note rests because there are x8 more than\n",
    "                # any other note\n",
    "                if note_length != '16th':\n",
    "                    notes.append('R-'+note_length)\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                raise TypeError('Invalid Note:{}'.format(element))\n",
    "                break\n",
    "            durations.append(note_length)    \n",
    "    pp += 1\n",
    "print(round(100*pp/156,2),'% of songs converted successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 88 keys, so 88 classes. There are also 12 types of rests, resulting in exactly 100 classes\n",
    "NUM_KEYS = 88\n",
    "NUM_RESTS = 12\n",
    "NUM_CLASS = NUM_KEYS + NUM_RESTS\n",
    "\n",
    "note_dict = {\n",
    "        'A':0,\n",
    "        'B':2,\n",
    "        'C':3,\n",
    "        'D':5,\n",
    "        'E':7,\n",
    "        'F':8,\n",
    "        'G':10\n",
    "}\n",
    "\n",
    "reverse_note_dict = {v: k for k, v in note_dict.items()}\n",
    "\n",
    "rest_dict = {\n",
    "    'duplex-maxima':0,\n",
    "    'maxima':1,\n",
    "    'longa':2,\n",
    "    'breve':3,\n",
    "    'whole': 4,\n",
    "    'half': 5,\n",
    "    'quarter':6,\n",
    "    'eighth':7,\n",
    "    '16th':8,\n",
    "    'zero':9,\n",
    "    'complex':10,\n",
    "    'inexpressible':11\n",
    "}\n",
    "\n",
    "reverse_rest_dict = {v: k for k, v in rest_dict.items()}\n",
    "\n",
    "def note_encoder(note21, return_index=False):\n",
    "    import re\n",
    "    one_hot_matrix = np.zeros(NUM_CLASS)\n",
    "    \n",
    "    # If the note is a rest:\n",
    "    if 'R' in note21:\n",
    "        if ('32nd' in note21) or ('duplex' in note21):\n",
    "            rest_length = 'complex'\n",
    "        else:\n",
    "            rest_length = re.findall(f'R-([a-z]*)',note21)[0]\n",
    "\n",
    "        indx = NUM_KEYS + rest_dict[rest_length]\n",
    "        \n",
    "    # If a note:\n",
    "    else:\n",
    "        octave = int(re.findall(f'[0-9]',note21)[0])\n",
    "        if octave == 9:\n",
    "            octave = 6\n",
    "        note = re.findall(f'[A-G]',note21)[0]\n",
    "\n",
    "        if octave == 0:\n",
    "            indx = note_dict[note]\n",
    "        else: \n",
    "            indx = note_dict[note]+12*(octave-1)\n",
    "\n",
    "        if len(note21) != 2: #There's a flat or sharp\n",
    "            if '#' in note21:\n",
    "                indx+=1\n",
    "            elif '-' in note21:\n",
    "                indx-=1\n",
    "            else:\n",
    "                raise TypeError('Unkown string input')\n",
    "    one_hot_matrix[indx] = 1\n",
    "    \n",
    "    if return_index:\n",
    "        return(indx)\n",
    "    else:\n",
    "        return(one_hot_matrix)\n",
    "\n",
    "def one_hot_note_encoder(note21):\n",
    "    if isinstance(note21,str):\n",
    "        one_hot_matrix = note_encoder(note21)\n",
    "    elif isinstance(note21,list):\n",
    "        one_hot_matrix = np.zeros(NUM_CLASS)\n",
    "        for note in note21:\n",
    "            one_hot_matrix+=note_encoder(note)\n",
    "            \n",
    "    return(one_hot_matrix)\n",
    "\n",
    "# Function added for 6 Feature; return_index flag also added to be lazy\n",
    "def note_to_int(note21):\n",
    "    note_int = []\n",
    "    if isinstance(note21,str):\n",
    "        note_int.append(note_encoder(note21,return_index=True))\n",
    "    elif isinstance(note21,list):\n",
    "        note_int = []\n",
    "        for chord_note in note21[:6]:\n",
    "            note_int.append(note_encoder(chord_note,return_index=True))\n",
    "       \n",
    "    while len(note_int) < 6:\n",
    "        note_int.append(-1)\n",
    "        \n",
    "    return(note_int)\n",
    "\n",
    "def note_decoder(indx):    \n",
    "    \n",
    "    if indx >= NUM_KEYS:\n",
    "        decoded = reverse_rest_dict[indx-NUM_KEYS]\n",
    "    else:\n",
    "        decoded = []\n",
    "        notes_played = np.argwhere(encoded_notes[i] == np.amax(encoded_notes[i]))\n",
    "        for note in notes_played:\n",
    "            t = note[0]\n",
    "            # print(t)\n",
    "            octave = 1\n",
    "            accent = ''\n",
    "            while t > 11:\n",
    "                t -= 12\n",
    "                octave += 1\n",
    "\n",
    "            if (t == 4) or (t == 11) or (t == 9):\n",
    "                accent = '#'\n",
    "                t-= 1\n",
    "\n",
    "            elif (t == 1) or (t == 6):\n",
    "                accent = '-'\n",
    "                t += 1\n",
    "\n",
    "            guess = reverse_note_dict[t] + accent + str(octave)\n",
    "            decoded.append(guess)\n",
    "        if len(decoded) == 1:\n",
    "            decoded = decoded[0]\n",
    "            \n",
    "    return(decoded)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = np.zeros(NUM_CLASS)\n",
    "int_notes = [note_to_int(i) for i in notes]\n",
    "total_count = 0\n",
    "for note in int_notes:\n",
    "    for i in note:\n",
    "        if i < 0:\n",
    "            break\n",
    "        else:\n",
    "            class_counts[i] += 1\n",
    "            total_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should I make class weights by number of notes or chords? (chose notes)\n",
    "class_weights = (total_count-class_counts)/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 0.99925107, 1.        , 0.91511287,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 0.97370553, 0.99427456, 0.96640038,\n",
       "       1.        , 1.        , 0.9984653 , 0.99709022, 0.98391638,\n",
       "       0.99502349, 0.99294449, 0.98942083, 0.99615303, 0.94078118,\n",
       "       0.98331478, 0.94195164, 0.9776671 , 0.9882831 , 0.96603205,\n",
       "       0.99182723, 0.94279061, 0.97301799, 0.97740518, 0.96017565,\n",
       "       0.97600553, 0.97008774, 0.99395125, 0.98345393, 0.95776925,\n",
       "       0.96773864, 0.96058081, 0.98580304, 0.91223583, 0.97070571,\n",
       "       0.95930804, 0.96880269, 0.9812235 , 0.99976673, 1.        ,\n",
       "       0.99998363, 0.99303862, 0.99490481, 0.99497029, 0.99828523,\n",
       "       0.99587064, 0.99875587, 0.99834253, 0.99933292, 0.99974217,\n",
       "       1.        , 1.        , 0.99987313, 0.99997954, 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 0.99999181,\n",
       "       0.99984039, 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 0.99997954,\n",
       "       1.        , 1.        , 0.99999591, 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 0.99995907,\n",
       "       0.99993043, 0.99993452, 0.99986085, 0.9997831 , 0.99964395,\n",
       "       0.99840801, 1.        , 1.        , 0.99773683, 0.99941886])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 163463,\n",
       "         3: 3179,\n",
       "         4: 6476,\n",
       "         2: 6503,\n",
       "         5: 3952,\n",
       "         6: 2108,\n",
       "         10: 2,\n",
       "         12: 2,\n",
       "         7: 1})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "ma_list = []\n",
    "for i in notes:\n",
    "    if isinstance(i,list):\n",
    "        ma_list.append(len(i))\n",
    "    else:\n",
    "        ma_list.append(1)\n",
    "Counter(ma_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- Encoder/Decoder for multiclass keyboarding **[DONE]**\n",
    "- 100 feature input **[DONE/FAILED]**\n",
    "- 6 Note capped feature input (for guitar strings) ** IN PROGRESS **\n",
    "- Starts/Ends (easy add)\n",
    "- Class Weighting **[DONE]**\n",
    "- Stateful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185586 training examples\n"
     ]
    }
   ],
   "source": [
    "# create input/output sequences -- output is next note \n",
    "\n",
    "sequence_length = 100\n",
    "\n",
    "network_input = []\n",
    "network_output = []\n",
    "network_output_note = []\n",
    "network_output_duration = []\n",
    "\n",
    "encoded_notes = [one_hot_note_encoder(note) for note in notes]\n",
    "int_notes = [note_to_int(note) for note in notes]\n",
    "\n",
    "# create input sequences and the corresponding outputs\n",
    "for i in range(0, len(notes) - sequence_length,1):\n",
    "    \n",
    "    sequence_in = int_notes[i:i + sequence_length]\n",
    "    sequence_out = encoded_notes[i + sequence_length]\n",
    "\n",
    "    network_input.append(sequence_in)\n",
    "    network_output.append(sequence_out)\n",
    "    \n",
    "network_output_np = np.array(network_output)\n",
    "network_input_np = np.array(network_input)\n",
    "\n",
    "n_patterns = len(network_input)\n",
    "print(n_patterns, 'training examples')\n",
    "\n",
    "# reshape the input into a format compatible with LSTM layers\n",
    "\n",
    "## I now have 6 features for max 6 note cords\n",
    "network_input = np.reshape(network_input_np, (n_patterns, sequence_length,6))\n",
    "network_output = network_output_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.models import Input\n",
    "from keras.layers import LSTM, Masking\n",
    "\n",
    "# Rewritten with Keras' functional API\n",
    "model_input = Input(shape=(network_input.shape[1], network_input.shape[2]))\n",
    "\n",
    "layers = Masking(mask_value=-1)(model_input)\n",
    "\n",
    "# layers = LSTM(NUM_CLASS,return_sequences=True)(model_input)\n",
    "layers = Dropout(0.5)(layers)\n",
    "# layers = LSTM(20)(layers)\n",
    "\n",
    "layers = LSTM(sequence_length)(layers)\n",
    "\n",
    "output_note = Dense(NUM_CLASS)(layers)\n",
    "model = Model(inputs=model_input, outputs=output_note)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "185586/185586 [==============================] - 146s 784us/step - loss: 10.5937 - acc: 0.1203\n",
      "Epoch 2/2\n",
      "185586/185586 [==============================] - 147s 791us/step - loss: 10.6173 - acc: 0.1203\n"
     ]
    }
   ],
   "source": [
    "filepath = \"weights/test_weights_v3.hdf5\"    \n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath, monitor='loss', \n",
    "    verbose=0,        \n",
    "    save_best_only=True,        \n",
    "    mode='min'\n",
    ")    \n",
    "callbacks_list = [checkpoint]     \n",
    "history = model.fit(network_input, network_output, epochs=2, batch_size=264, \n",
    "                    class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_loss += history.history['loss']\n",
    "old_acc += history.history['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.585485398713494,\n",
       " 10.693864449224193,\n",
       " 10.614373543318674,\n",
       " 10.5693463446394,\n",
       " 10.593745114403958,\n",
       " 10.617298717491996]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.11498712218527318,\n",
       " 0.11581153793280388,\n",
       " 0.1188936668872787,\n",
       " 0.12060715822256493,\n",
       " 0.1203161876400922,\n",
       " 0.1203000225361117]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random start sequence\n",
    "start = np.random.randint(0, len(network_input)-1)\n",
    "pattern = network_input[start]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4',\n",
       " 'F#4']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_output = []\n",
    "\n",
    "# Pick a random start sequence\n",
    "start = np.random.randint(0, len(network_input)-1)\n",
    "pattern = network_input[start]\n",
    "\n",
    "# generate 500 notes\n",
    "for note_index in range(100):\n",
    "    \n",
    "    # Reshape and scale sequence\n",
    "#     prediction_input = np.reshape(pattern, (1,pattern.shape[0],pattern.shape[1]))\n",
    "    prediction_input = np.reshape(pattern, (1, sequence_length,6))\n",
    "    \n",
    "    # Predict next note\n",
    "    note_prediction = model.predict(prediction_input, verbose=0)\n",
    "    \n",
    "    # Best Note:\n",
    "    note_draw = np.argmax(note_prediction)\n",
    "    note_str = note_decoder(note_draw)\n",
    "    \n",
    "    if isinstance(note_draw,list):\n",
    "        note_list = note_draw\n",
    "    else:\n",
    "        note_list = []\n",
    "        note_list.append(note_draw)\n",
    "    while len(note_list) < 6:\n",
    "        note_list.append(-1)\n",
    "    \n",
    "    # Add note to our new sequence \n",
    "    \n",
    "    new_pattern = prediction_input\n",
    "    new_pattern = np.append(new_pattern,note_list)\n",
    "    new_pattern = np.delete(new_pattern,[i for i in range(6)]).reshape(100,6)\n",
    "    \n",
    "    \n",
    "    pattern = new_pattern\n",
    "    \n",
    "    prediction_output.append(note_str)\n",
    "prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
