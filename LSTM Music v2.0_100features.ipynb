{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras==2.1.1 in /anaconda3/lib/python3.6/site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /anaconda3/lib/python3.6/site-packages (from keras==2.1.1) (1.14.3)\n",
      "Requirement already satisfied: pyyaml in /anaconda3/lib/python3.6/site-packages (from keras==2.1.1) (3.12)\n",
      "Requirement already satisfied: scipy>=0.14 in /anaconda3/lib/python3.6/site-packages (from keras==2.1.1) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /anaconda3/lib/python3.6/site-packages (from keras==2.1.1) (1.11.0)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==1.4.0 in /anaconda3/lib/python3.6/site-packages (1.4.0)\n",
      "Requirement already satisfied: numpy>=1.12.1 in /anaconda3/lib/python3.6/site-packages (from tensorflow==1.4.0) (1.14.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /anaconda3/lib/python3.6/site-packages (from tensorflow==1.4.0) (0.31.1)\n",
      "Requirement already satisfied: protobuf>=3.3.0 in /anaconda3/lib/python3.6/site-packages (from tensorflow==1.4.0) (3.6.1)\n",
      "Requirement already satisfied: enum34>=1.1.6 in /anaconda3/lib/python3.6/site-packages (from tensorflow==1.4.0) (1.1.6)\n",
      "Requirement already satisfied: six>=1.10.0 in /anaconda3/lib/python3.6/site-packages (from tensorflow==1.4.0) (1.11.0)\n",
      "Requirement already satisfied: tensorflow-tensorboard<0.5.0,>=0.4.0rc1 in /anaconda3/lib/python3.6/site-packages (from tensorflow==1.4.0) (0.4.0)\n",
      "Requirement already satisfied: setuptools in /anaconda3/lib/python3.6/site-packages (from protobuf>=3.3.0->tensorflow==1.4.0) (39.1.0)\n",
      "Requirement already satisfied: html5lib==0.9999999 in /anaconda3/lib/python3.6/site-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.0) (0.9999999)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /anaconda3/lib/python3.6/site-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.0) (3.0.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /anaconda3/lib/python3.6/site-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.0) (0.14.1)\n",
      "Requirement already satisfied: bleach==1.5.0 in /anaconda3/lib/python3.6/site-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.0) (1.5.0)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upcoming Modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Change: Add Rests as notes\n",
    "for element in notes_to_parse:\n",
    "    if isinstance(element, note.Note):\n",
    "        notes.append(str(element.pitch))\n",
    " \n",
    "    elif isinstance(element,chord.Chord):\n",
    "        notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "        \n",
    "    elif isinstance(element,note.Rest):\n",
    "        notes.append(str('R'))\n",
    "# # Training Change: Add Start/End Markers\n",
    "\n",
    "# # Append the pitch of every note\n",
    "# notes.append('start')\n",
    "# for element in notes_to_parse:\n",
    "#     ...\n",
    "#     #stuff\n",
    "# notes.append('end')\n",
    "\n",
    "# Feature Add: Duration\n",
    "note = notes_to_parse[7]\n",
    "print('Note Length:', note.duration.type)\n",
    "rest = notes_to_parse[6]\n",
    "print('Rest Length:', rest.duration.type)\n",
    "\n",
    "# Feature Add: Offset Change\n",
    "# Is this a feature? Or is this inherent to duration (i.e I can just add this appropriately afterwards?)\n",
    "# ANSWER: Doesn't look like it\n",
    "last_offset = 0\n",
    "offsets = []\n",
    "for element in notes_to_parse:\n",
    "    if isinstance(element, note.Note):\n",
    "        notes.append(str(element.pitch))\n",
    " \n",
    "    elif isinstance(element,chord.Chord):\n",
    "        notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "        \n",
    "    elif isinstance(element,note.Rest):\n",
    "        notes.append(str('R'))\n",
    "    \n",
    "    offset_delta = element.offset - last_offset\n",
    "    if offset_delta < 0:\n",
    "        print(offset_delta)\n",
    "        break\n",
    "    offsets.append(offset_delta)\n",
    "    last_offset = element.offset\n",
    "\n",
    "... \n",
    "x = note.Note('A3')\n",
    "x.offset = 0.5\n",
    "\n",
    "from collections import Counter\n",
    "Counter(offsets)\n",
    "\n",
    "# Model Change: Stateful\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "pkg_resources.require('tensorflow==1.4.0')\n",
    "pkg_resources.require('keras==2.1.1')\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "from keras.utils import to_categorical\n",
    "from keras import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, Activation\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midi_songs/Cids.mid\n",
      "midi_songs/JENOVA.mid\n"
     ]
    }
   ],
   "source": [
    "notes = []\n",
    "durations = []\n",
    "pp = 0\n",
    "for file in glob.glob(\"midi_songs/*.mid\"):\n",
    "    midi = converter.parse(file)\n",
    "    notes_to_parse = None\n",
    "    \n",
    "    parts = instrument.partitionByInstrument(midi)\n",
    "    \n",
    "    if parts: # file has instrument parts\n",
    "        notes_to_parse = parts.parts[0].recurse()\n",
    "    else:\n",
    "        notes_to_parse = midi.flat.notes\n",
    "        \n",
    "    # Append the pitch and duration of every note\n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note) or isinstance(element,chord.Chord) or isinstance(element,note.Rest):\n",
    "            \n",
    "            # music21 can't handle notes beyond a certain speed. This skips them\n",
    "            # In the original run, there was only 1 note in 2 files that broke it\n",
    "            try:\n",
    "                note_length = element.duration.type\n",
    "            except: # This is naked because the except raised by music21 is custom \n",
    "                print(file)\n",
    "                continue\n",
    "            \n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            # If chord, encode ID of every note in cord separated by .\n",
    "            elif isinstance(element,chord.Chord):\n",
    "                chord_notes = [str(n) for n in element.pitches]\n",
    "                notes.append(chord_notes)\n",
    "            elif isinstance(element,note.Rest):\n",
    "                # Sorry, I'm going to clear out 16th note rests because there are x8 more than\n",
    "                # any other note\n",
    "                if note_length != '16th':\n",
    "                    notes.append('R-'+note_length)\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                raise TypeError('Invalid Note:{}'.format(element))\n",
    "                break\n",
    "            durations.append(note_length)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 88 keys, so 88 classes. There are also 12 types of rests, resulting in exactly\n",
    "# 100 classes\n",
    "NUM_KEYS = 88\n",
    "NUM_RESTS = 12\n",
    "NUM_CLASS = NUM_KEYS + NUM_RESTS\n",
    "\n",
    "note_dict = {\n",
    "        'A':0,\n",
    "        'B':2,\n",
    "        'C':3,\n",
    "        'D':5,\n",
    "        'E':7,\n",
    "        'F':8,\n",
    "        'G':10\n",
    "}\n",
    "\n",
    "reverse_note_dict = {v: k for k, v in note_dict.items()}\n",
    "\n",
    "rest_dict = {\n",
    "    'duplex-maxima':0,\n",
    "    'maxima':1,\n",
    "    'longa':2,\n",
    "    'breve':3,\n",
    "    'whole': 4,\n",
    "    'half': 5,\n",
    "    'quarter':6,\n",
    "    'eighth':7,\n",
    "    '16th':8,\n",
    "    'zero':9,\n",
    "    'complex':10,\n",
    "    'inexpressible':11\n",
    "}\n",
    "\n",
    "reverse_rest_dict = {v: k for k, v in rest_dict.items()}\n",
    "\n",
    "def note_encoder(note21, return_index=False):\n",
    "    import re\n",
    "    one_hot_matrix = np.zeros(NUM_CLASS)\n",
    "    \n",
    "    # If the note is a rest:\n",
    "    if 'R' in note21:\n",
    "        if ('32nd' in note21) or ('duplex' in note21):\n",
    "            rest_length = 'complex'\n",
    "        else:\n",
    "            rest_length = re.findall(f'R-([a-z]*)',note21)[0]\n",
    "\n",
    "        indx = NUM_KEYS + rest_dict[rest_length]\n",
    "        \n",
    "    # If a note:\n",
    "    else:\n",
    "        octave = int(re.findall(f'[0-9]',note21)[0])\n",
    "        note = re.findall(f'[A-G]',note21)[0]\n",
    "\n",
    "        if octave == 0:\n",
    "            indx = note_dict[note]\n",
    "        else: \n",
    "            indx = note_dict[note]+12*(octave-1)\n",
    "\n",
    "        if len(note21) != 2: #There's a flat or sharp\n",
    "            if '#' in note21:\n",
    "                indx+=1\n",
    "            elif '-' in note21:\n",
    "                indx-=1\n",
    "            else:\n",
    "                raise TypeError('Unkown string input')\n",
    "    one_hot_matrix[indx] = 1\n",
    "    \n",
    "    if return_index:\n",
    "        return(indx)\n",
    "    else:\n",
    "        return(one_hot_matrix)\n",
    "\n",
    "def one_hot_note_encoder(note21):\n",
    "    if isinstance(note21,str):\n",
    "        one_hot_matrix = note_encoder(note21)\n",
    "    elif isinstance(note21,list):\n",
    "        one_hot_matrix = np.zeros(NUM_CLASS)\n",
    "        for note in note21:\n",
    "            one_hot_matrix+=note_encoder(note)\n",
    "            \n",
    "    return(one_hot_matrix)\n",
    "\n",
    "# Function added for 6 Feature; return_index flag also added to be lazy\n",
    "def note_to_int(note21):\n",
    "    note_int = []\n",
    "    if isinstance(note21,str):\n",
    "        note_int.append(note_encoder(note21,return_index=True))\n",
    "    elif isinstance(note21,list):\n",
    "        note_int = []\n",
    "        for chord_note in note21[:6]:\n",
    "            note_int.append(note_encoder(chord_note,return_index=True))\n",
    "       \n",
    "    while len(note_int) < 6:\n",
    "        note_int.append(0)\n",
    "        \n",
    "    return(note_int)\n",
    "\n",
    "def note_decoder(indx):    \n",
    "    \n",
    "    if indx > NUM_KEYS:\n",
    "        decoded = reverse_rest_dict[indx-NUM_KEYS]\n",
    "    else:\n",
    "        decoded = []\n",
    "        notes_played = np.argwhere(encoded_notes[i] == np.amax(encoded_notes[i]))\n",
    "        for note in notes_played:\n",
    "            t = note[0]\n",
    "            # print(t)\n",
    "            octave = 1\n",
    "            accent = ''\n",
    "            while t > 11:\n",
    "                t -= 12\n",
    "                octave += 1\n",
    "\n",
    "            if (t == 4) or (t == 11) or (t == 9):\n",
    "                accent = '#'\n",
    "                t-= 1\n",
    "\n",
    "            elif (t == 1) or (t == 6):\n",
    "                accent = '-'\n",
    "                t += 1\n",
    "\n",
    "            guess = reverse_note_dict[t] + accent + str(octave)\n",
    "            decoded.append(guess)\n",
    "        if len(decoded) == 1:\n",
    "            decoded = decoded[0]\n",
    "            \n",
    "    return(decoded)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 18614, 4: 732, 3: 4369, 5: 47, 6: 18, 7: 8, 8: 2})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_list = []\n",
    "for i in notes:\n",
    "    if isinstance(i,list):\n",
    "        ma_list.append(len(i))\n",
    "Counter(ma_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- Encoder/Decoder for multiclass keyboarding **[DONE]**\n",
    "- 100 feature input **[DONE/FAILED]**\n",
    "- 6 Note capped feature input (for guitar strings) ** IN PROGRESS **\n",
    "- Starts/Ends || End predictor machine (logress, with boost to precision)\n",
    "- Masking layer to get rid of the nans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100 features Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85765 training examples\n"
     ]
    }
   ],
   "source": [
    "# create input/output sequences -- output is next note \n",
    "\n",
    "sequence_length = 100\n",
    "\n",
    "network_input = []\n",
    "network_output = []\n",
    "network_output_note = []\n",
    "network_output_duration = []\n",
    "\n",
    "encoded_notes = [one_hot_note_encoder(note) for note in notes]\n",
    "\n",
    "# create input sequences and the corresponding outputs\n",
    "for i in range(0, len(notes) - sequence_length,1):\n",
    "    sequence_in = encoded_notes[i:i + sequence_length]\n",
    "#     duration_in = durations[i:i+sequence_length]\n",
    "    \n",
    "    sequence_out = encoded_notes[i + sequence_length]\n",
    "#     duration_out = durations[i + sequence_length]\n",
    "\n",
    "    network_input.append(sequence_in)\n",
    "    network_output.append(sequence_out)\n",
    "    \n",
    "network_output_np = np.array(network_output)\n",
    "network_input_np = np.array(network_input)\n",
    "\n",
    "n_patterns = len(network_input)\n",
    "print(n_patterns, 'training examples')\n",
    "\n",
    "# reshape the input into a format compatible with LSTM layers\n",
    "\n",
    "## TODO: I now have 100 features (?) for every note + rest style. Let's see if this works\n",
    "network_input = np.reshape(network_input_np, (n_patterns, sequence_length,NUM_CLASS))\n",
    "network_output = network_output_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((85765, 100, 100), (85765, 100))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_input.shape, network_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.models import Input\n",
    "\n",
    "# Rewritten with Keras' functional API\n",
    "model_input = Input(shape=(network_input.shape[1], network_input.shape[2]))\n",
    "\n",
    "# layers = LSTM(NUM_CLASS,return_sequences=True)(model_input)\n",
    "# layers = Dropout(0.3)(layers)\n",
    "# layers = LSTM(20)(layers)\n",
    "\n",
    "layers = LSTM(NUM_CLASS)(model_input)\n",
    "\n",
    "output_note = Dense(NUM_CLASS)(layers)\n",
    "model = Model(inputs=model_input, outputs=output_note)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "85765/85765 [==============================] - 88s 1ms/step - loss: 11.6020\n",
      "Epoch 2/10\n",
      "85765/85765 [==============================] - 83s 969us/step - loss: nan\n",
      "Epoch 3/10\n",
      "85765/85765 [==============================] - 9142s 107ms/step - loss: nan\n",
      "Epoch 4/10\n",
      "81920/85765 [===========================>..] - ETA: 3s - loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-8c404bc345ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m )    \n\u001b[1;32m      8\u001b[0m \u001b[0mcallbacks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2352\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filepath = \"weights/test_weights_v2_0_100f.hdf5\"    \n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath, monitor='loss', \n",
    "    verbose=0,        \n",
    "    save_best_only=True,        \n",
    "    mode='min'\n",
    ")    \n",
    "callbacks_list = [checkpoint]     \n",
    "model.fit(network_input, network_output, epochs=10, batch_size=256, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85765 training examples\n"
     ]
    }
   ],
   "source": [
    "# create input/output sequences -- output is next note \n",
    "\n",
    "sequence_length = 100\n",
    "\n",
    "network_input = []\n",
    "network_output = []\n",
    "network_output_note = []\n",
    "network_output_duration = []\n",
    "\n",
    "encoded_notes = [one_hot_note_encoder(note) for note in notes]\n",
    "int_notes = [note_to_int(note) for note in notes]\n",
    "\n",
    "# create input sequences and the corresponding outputs\n",
    "for i in range(0, len(notes) - sequence_length,1):\n",
    "    \n",
    "    sequence_in = int_notes[i:i + sequence_length]\n",
    "    sequence_out = encoded_notes[i + sequence_length]\n",
    "\n",
    "    network_input.append(sequence_in)\n",
    "    network_output.append(sequence_out)\n",
    "    \n",
    "network_output_np = np.array(network_output)\n",
    "network_input_np = np.array(network_input)\n",
    "\n",
    "n_patterns = len(network_input)\n",
    "print(n_patterns, 'training examples')\n",
    "\n",
    "# reshape the input into a format compatible with LSTM layers\n",
    "\n",
    "## I now have 6 features for max 6 note cords\n",
    "network_input = np.reshape(network_input_np, (n_patterns, sequence_length,6))\n",
    "network_output = network_output_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.models import Input\n",
    "\n",
    "# Rewritten with Keras' functional API\n",
    "model_input = Input(shape=(network_input.shape[1], network_input.shape[2]))\n",
    "\n",
    "# layers = LSTM(NUM_CLASS,return_sequences=True)(model_input)\n",
    "# layers = Dropout(0.3)(layers)\n",
    "# layers = LSTM(20)(layers)\n",
    "\n",
    "layers = LSTM(sequence_length)(model_input)\n",
    "\n",
    "output_note = Dense(NUM_CLASS)(layers)\n",
    "model = Model(inputs=model_input, outputs=output_note)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "85765/85765 [==============================] - 57s 667us/step - loss: 11.5974\n",
      "Epoch 2/5\n",
      "85765/85765 [==============================] - 58s 678us/step - loss: 11.3151\n",
      "Epoch 3/5\n",
      "85765/85765 [==============================] - 57s 665us/step - loss: 11.2911\n",
      "Epoch 4/5\n",
      "85765/85765 [==============================] - 57s 668us/step - loss: 11.3698\n",
      "Epoch 5/5\n",
      "85765/85765 [==============================] - 57s 667us/step - loss: 11.3307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xd1c8e8cc0>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"weights/test_weights_v2_0_6f.hdf5\"    \n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath, monitor='loss', \n",
    "    verbose=0,        \n",
    "    save_best_only=True,        \n",
    "    mode='min'\n",
    ")    \n",
    "callbacks_list = [checkpoint]     \n",
    "model.fit(network_input, network_output, epochs=5, batch_size=256, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random start sequence\n",
    "start = np.random.randint(0, len(network_input)-1)\n",
    "pattern = network_input[start]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4',\n",
       " 'C4']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_output = []\n",
    "\n",
    "# Pick a random start sequence\n",
    "start = np.random.randint(0, len(network_input)-1)\n",
    "pattern = network_input[start]\n",
    "\n",
    "# generate 500 notes\n",
    "for note_index in range(100):\n",
    "    \n",
    "    # Reshape and scale sequence\n",
    "#     prediction_input = np.reshape(pattern, (1,pattern.shape[0],pattern.shape[1]))\n",
    "    prediction_input = np.reshape(pattern, (1, sequence_length,6))\n",
    "    \n",
    "    # Predict next note\n",
    "    note_prediction = model.predict(prediction_input, verbose=0)\n",
    "    \n",
    "    # Best Note:\n",
    "    note_draw = np.argmax(note_prediction)\n",
    "    note_str = note_decoder(note_draw)\n",
    "    \n",
    "    if isinstance(note_draw,list):\n",
    "        note_list = note_draw\n",
    "    else:\n",
    "        note_list = []\n",
    "        note_list.append(note_draw)\n",
    "    while len(note_list) < 6:\n",
    "        note_list.append(0)\n",
    "    \n",
    "    # Add note to our new sequence \n",
    "    \n",
    "    new_pattern = prediction_input\n",
    "    new_pattern = np.append(new_pattern,note_list)\n",
    "    new_pattern = np.delete(new_pattern,[i for i in range(6)]).reshape(100,6)\n",
    "    \n",
    "    \n",
    "    pattern = new_pattern\n",
    "    \n",
    "    prediction_output.append(note_str)\n",
    "prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'eighth': 36476, '16th': 32447, 'quarter': 7575, 'zero': 3777, 'half': 2871, 'complex': 1845, 'whole': 532, 'inexpressible': 119, '32nd': 116, 'breve': 59, 'longa': 31, 'maxima': 9, 'duplex-maxima': 8})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(durations))\n",
    "duration_dict = {\n",
    "    'duplex-maxima':16.0,\n",
    "    'maxima':8.0,\n",
    "    'longa':4.0,\n",
    "    'breve':2.0,\n",
    "    'whole': 1.0,\n",
    "    'half': 0.5,\n",
    "    'quarter':0.25,\n",
    "    'eighth':0.125,\n",
    "    '16th':0.0625,\n",
    "    'zero':0.0,\n",
    "    'complex':0.03125,\n",
    "    'inexpressible':0.0155\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('E-5', 1675),\n",
       " ('3.7', 1795),\n",
       " ('E-3', 1855),\n",
       " ('C3', 1877),\n",
       " ('F5', 1972),\n",
       " ('D3', 2038),\n",
       " ('D4', 2189),\n",
       " ('B-2', 2338),\n",
       " ('C4', 2345),\n",
       " ('B-3', 2776)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_by_value = sorted(Counter(notes).items(), key=lambda kv: kv[1])\n",
    "sorted_by_value[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string notes into integers for stronger LSTM performance\n",
    "\n",
    "# get all pitch names\n",
    "pitchnames = sorted(set(item for item in notes))\n",
    "durationnames = sorted(set(item for item in durations))\n",
    "\n",
    "# create a dictionary to map pitches to integers\n",
    "note_to_int = dict((note,number) for number, note in enumerate(pitchnames))\n",
    "duration_to_int = dict((duration,number) for number, duration in enumerate(durationnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note_to_int['R-quarter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85765 training examples\n",
      "Input Shape: (85765, 100, 2)\n",
      "Output #1 Shape: (85765, 369)\n",
      "Output #1 Shape: (85765, 13)\n"
     ]
    }
   ],
   "source": [
    "n_vocab = len(note_to_int)\n",
    "n_duration = len(duration_dict)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# create input/output sequences -- output is next note \n",
    "\n",
    "sequence_length = 100\n",
    "\n",
    "network_input = []\n",
    "network_output = []\n",
    "network_output_note = []\n",
    "network_output_duration = []\n",
    "\n",
    "# create input sequences and the corresponding outputs\n",
    "for i in range(0, len(notes) - sequence_length,1):\n",
    "    sequence_in = notes[i:i + sequence_length]\n",
    "    duration_in = durations[i:i+sequence_length]\n",
    "    \n",
    "    sequence_out = notes[i + sequence_length]\n",
    "    duration_out = durations[i + sequence_length]\n",
    "    \n",
    "    sequence_in = [note_to_int[char] for char in sequence_in]\n",
    "    duration_in = [duration_to_int[char] for char in duration_in]\n",
    "    \n",
    "    zipped_in = [[note, duration] for note,duration in zip(sequence_in,duration_in)]\n",
    "#     zipped_out = [note_to_int[sequence_out],duration_out]\n",
    "    \n",
    "    network_input.append(zipped_in)\n",
    "#     network_output.append(note_to_int[sequence_out])\n",
    "#     network_output_note.append(zipped_out)\n",
    "    network_output_note.append(note_to_int[sequence_out])\n",
    "    network_output_duration.append(duration_to_int[duration_out])\n",
    "    \n",
    "network_output_note = np.array(network_output_note)\n",
    "network_output_note = to_categorical(network_output_note)\n",
    "\n",
    "network_output_duration = np.array(network_output_duration)\n",
    "network_output_duration = to_categorical(network_output_duration)\n",
    "\n",
    "# network_output = np.array([[i,j] for i,j in zip(network_output_note,network_output_duration)])\n",
    "\n",
    "n_patterns = len(network_input)\n",
    "print(n_patterns, 'training examples')\n",
    "\n",
    "# reshape the input into a format compatible with LSTM layers\n",
    "network_input = np.reshape(network_input, (n_patterns, sequence_length,2))\n",
    "\n",
    "print('Input Shape:', network_input.shape)\n",
    "print('Output #1 Shape:', network_output_note.shape)\n",
    "print('Output #1 Shape:', network_output_duration.shape)\n",
    "\n",
    "# normalize input\n",
    "n_vocab = len(note_to_int)\n",
    "n_duration = len(durationnames)\n",
    "# network_input = network_input / float(n_vocab)\n",
    "\n",
    "# network_output = to_categorical(network_output)\n",
    "# network_output = np.reshape(network_output, (network_output.shape[0], 1, network_output.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# network_input[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.models import Input\n",
    "\n",
    "# Rewritten with Keras' functional API\n",
    "model_input = Input(shape=(network_input.shape[1], network_input.shape[2]))\n",
    "\n",
    "layers = LSTM(88,return_sequences=True)(model_input)\n",
    "layers = Dropout(0.3)(layers)\n",
    "layers = LSTM(20)(layers)\n",
    "\n",
    "\n",
    "output_note = Dense(n_vocab)(layers)\n",
    "output_duration = Dense(n_duration)(layers)\n",
    "\n",
    "model = Model(inputs=model_input, outputs=[output_note,output_duration])\n",
    "model.compile(loss=['categorical_crossentropy','categorical_crossentropy'], \n",
    "              optimizer='rmsprop',loss_weights = [1.0,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_24/BiasAdd:0' shape=(?, 13) dtype=float32>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_model = Sequential()\n",
    "note_model.add(LSTM(20,  \n",
    "               input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "               return_sequences=True))\n",
    "note_model.add(LSTM(20))\n",
    "note_model.add(Dense(n_vocab))\n",
    "note_model.add(Activation('softmax'))\n",
    "note_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "85765/85765 [==============================] - 52s 609us/step - loss: 3.3252\n",
      "Epoch 2/10\n",
      "85765/85765 [==============================] - 52s 610us/step - loss: 3.2758\n",
      "Epoch 3/10\n",
      "85765/85765 [==============================] - 52s 601us/step - loss: 3.2427\n",
      "Epoch 4/10\n",
      "85765/85765 [==============================] - 52s 610us/step - loss: 3.2962\n",
      "Epoch 5/10\n",
      "85765/85765 [==============================] - 52s 610us/step - loss: 3.2406\n",
      "Epoch 6/10\n",
      "85765/85765 [==============================] - 50s 588us/step - loss: 3.3594\n",
      "Epoch 7/10\n",
      "85765/85765 [==============================] - 52s 604us/step - loss: 3.2348\n",
      "Epoch 8/10\n",
      "85765/85765 [==============================] - 51s 591us/step - loss: 3.2166\n",
      "Epoch 9/10\n",
      "85765/85765 [==============================] - 50s 583us/step - loss: 3.2358\n",
      "Epoch 10/10\n",
      "85765/85765 [==============================] - 50s 586us/step - loss: 3.2245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xd22692518>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"weights/test_weights_v2_0_2_notes.hdf5\"    \n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath, monitor='loss', \n",
    "    verbose=0,        \n",
    "    save_best_only=True,        \n",
    "    mode='min'\n",
    ")    \n",
    "callbacks_list = [checkpoint]     \n",
    "note_model.fit(network_input, network_output_note, \\\n",
    "          epochs=10, batch_size=256, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_model = Sequential()\n",
    "duration_model.add(LSTM(20,  \n",
    "               input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "               return_sequences=True))\n",
    "duration_model.add(LSTM(20))\n",
    "duration_model.add(Dense(n_duration))\n",
    "duration_model.add(Activation('softmax'))\n",
    "duration_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "85765/85765 [==============================] - 50s 579us/step - loss: 0.6585\n",
      "Epoch 2/5\n",
      "85765/85765 [==============================] - 51s 600us/step - loss: 0.6552\n",
      "Epoch 3/5\n",
      "85765/85765 [==============================] - 49s 570us/step - loss: 0.6547\n",
      "Epoch 4/5\n",
      "85765/85765 [==============================] - 49s 572us/step - loss: 0.6485\n",
      "Epoch 5/5\n",
      "85765/85765 [==============================] - 49s 570us/step - loss: 0.6459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xd22692550>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"weights/test_weights_v2_0_2_durations.hdf5\"    \n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath, monitor='loss', \n",
    "    verbose=0,        \n",
    "    save_best_only=True,        \n",
    "    mode='min'\n",
    ")    \n",
    "callbacks_list = [checkpoint]     \n",
    "duration_model.fit(network_input, network_output_duration, \\\n",
    "          epochs=5, batch_size=256, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"weights/test_weights_v2_0_2.hdf5\"    \n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath, monitor='loss', \n",
    "    verbose=0,        \n",
    "    save_best_only=True,        \n",
    "    mode='min'\n",
    ")    \n",
    "callbacks_list = [checkpoint]     \n",
    "model.fit(network_input, [network_output_note,network_output_duration], \\\n",
    "          epochs=100, batch_size=256, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random start sequence\n",
    "start = np.random.randint(0, len(network_input)-1)\n",
    "pattern = network_input[start]\n",
    "\n",
    "# The reverse of note_to_int\n",
    "int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "int_to_duration = dict((number, duration) for number, duration in enumerate(durationnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2.5', '16th'],\n",
       " ['B-3', '16th'],\n",
       " ['D5', '16th'],\n",
       " ['E-5', '16th'],\n",
       " ['E-5', '16th'],\n",
       " ['F5', '16th'],\n",
       " ['2.5', '16th'],\n",
       " ['C#3', '16th'],\n",
       " ['2.5', '16th'],\n",
       " ['D3', 'zero'],\n",
       " ['2.7', 'zero'],\n",
       " ['D5', '16th'],\n",
       " ['5.10', 'zero'],\n",
       " ['7.8', '16th'],\n",
       " ['E-3', '16th'],\n",
       " ['3.7', '16th'],\n",
       " ['B-3', '16th'],\n",
       " ['G6', '16th'],\n",
       " ['G6', '16th'],\n",
       " ['7.10', '16th'],\n",
       " ['B-3', '16th'],\n",
       " ['R-32nd', '16th'],\n",
       " ['E-5', 'zero'],\n",
       " ['B-3', '16th'],\n",
       " ['G#6', '16th'],\n",
       " ['G#6', '16th'],\n",
       " ['G#6', '16th'],\n",
       " ['R-32nd', '16th'],\n",
       " ['C3', '16th'],\n",
       " ['G#6', '16th'],\n",
       " ['B-1', '16th'],\n",
       " ['B-1', '16th'],\n",
       " ['R-32nd', '16th'],\n",
       " ['F4', '16th'],\n",
       " ['F4', '16th'],\n",
       " ['F4', '16th'],\n",
       " ['C#4', '16th'],\n",
       " ['C5', '16th'],\n",
       " ['C5', '16th'],\n",
       " ['C5', '16th'],\n",
       " ['R-eighth', '16th'],\n",
       " ['D5', '16th'],\n",
       " ['F5', '16th'],\n",
       " ['F5', '16th'],\n",
       " ['F5', '16th'],\n",
       " ['F5', '16th'],\n",
       " ['G5', '16th'],\n",
       " ['B-4', '16th'],\n",
       " ['C5', '16th'],\n",
       " ['C5', '16th'],\n",
       " ['G5', '16th'],\n",
       " ['D5', '16th'],\n",
       " ['G#4', '16th'],\n",
       " ['G#4', '16th'],\n",
       " ['F5', '16th'],\n",
       " ['F5', '16th'],\n",
       " ['B-4', '16th'],\n",
       " ['F5', '16th'],\n",
       " ['F5', '16th'],\n",
       " ['F4', '16th'],\n",
       " ['F4', '16th'],\n",
       " ['F5', '16th'],\n",
       " ['F5', '16th'],\n",
       " ['F5', '16th'],\n",
       " ['F5', '16th'],\n",
       " ['F5', '16th'],\n",
       " ['F5', '16th'],\n",
       " ['F4', '16th'],\n",
       " ['F4', '16th'],\n",
       " ['B-4', '16th'],\n",
       " ['G#4', '16th'],\n",
       " ['R-eighth', '16th'],\n",
       " ['B-4', '16th'],\n",
       " ['D5', '16th'],\n",
       " ['10.2', '16th'],\n",
       " ['E-3', '16th'],\n",
       " ['G#4', '16th'],\n",
       " ['G#4', '16th'],\n",
       " ['F5', '16th'],\n",
       " ['F5', '16th'],\n",
       " ['F5', '16th'],\n",
       " ['F5', '16th'],\n",
       " ['F5', '16th'],\n",
       " ['B-4', '16th'],\n",
       " ['B-4', '16th'],\n",
       " ['B-4', '16th'],\n",
       " ['B-4', '16th'],\n",
       " ['C5', '16th'],\n",
       " ['G#4', '16th'],\n",
       " ['B-4', '16th'],\n",
       " ['F5', '16th'],\n",
       " ['F5', '16th'],\n",
       " ['F5', '16th'],\n",
       " ['F5', '16th'],\n",
       " ['F5', '16th'],\n",
       " ['F4', '16th'],\n",
       " ['B-4', '16th'],\n",
       " ['B-4', '16th'],\n",
       " ['F5', '16th'],\n",
       " ['F5', '16th']]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_output = []\n",
    "\n",
    "# generate 500 notes\n",
    "for note_index in range(100):\n",
    "    \n",
    "    # Reshape and scale sequence\n",
    "    prediction_input = np.reshape(pattern, (1,pattern.shape[0],pattern.shape[1]))\n",
    "    \n",
    "    # Predict next note\n",
    "    note_prediction = note_model.predict(prediction_input, verbose=0)\n",
    "    duration_prediction = duration_model.predict(prediction_input, verbose=0)\n",
    "    \n",
    "    # Best Note:\n",
    "    note_draw = np.argmax(note_prediction)\n",
    "    duration_draw = np.argmax(duration_prediction)\n",
    "    \n",
    "    result_draw = [note_draw,duration_draw]\n",
    "    \n",
    "    # Add note to our new sequence \n",
    "    note_result = int_to_note[note_draw]\n",
    "    duration_result = int_to_duration[duration_draw]\n",
    "    \n",
    "    result = [note_result,duration_result]\n",
    "    \n",
    "    new_pattern = prediction_input\n",
    "    new_pattern = np.append(new_pattern,result_draw)\n",
    "    new_pattern = np.delete(new_pattern,[0,1]).reshape(100,2)\n",
    "    \n",
    "    pattern = new_pattern\n",
    "    \n",
    "    \n",
    "    prediction_output.append(result)\n",
    "prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 0\n",
    "output_notes = []\n",
    "\n",
    "for pattern in prediction_output:\n",
    "    next_note = pattern[0]\n",
    "    next_duration = pattern[1]\n",
    "    \n",
    "    if ('.' in next_note) or next_note.isdigit():\n",
    "        notes_in_chord = next_note.split('.')\n",
    "        notes = []\n",
    "        for current_note in notes_in_chord:\n",
    "            single_note = note.Note(int(current_note))\n",
    "            single_note.storedInstrument = instrument.Piano()\n",
    "            notes.append(single_note)\n",
    "        new_note = chord.Chord(notes)\n",
    "    elif 'R' in next_note:\n",
    "        new_note = note.Rest()\n",
    "    # pattern is a note\n",
    "    else:\n",
    "        new_note = note.Note(next_note)\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "    \n",
    "    if next_duration != 'zero':\n",
    "        new_note.duration.type = next_duration\n",
    " \n",
    "        if next_duration == '16th':\n",
    "            offset += 0.125*3\n",
    "        elif next_duration == 'eighth':\n",
    "            offset += 0.25*3\n",
    "        elif next_duration == 'quarter':\n",
    "            offset += 0.5*3\n",
    "        elif next_duration == 'half':\n",
    "            offset += 1.0*3\n",
    "        elif next_duration == 'whole':\n",
    "            offset += 2.0*3\n",
    "    \n",
    "    new_note.offset = offset\n",
    "    output_notes.append(new_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'v2_0_2.mid'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midi_stream = stream.Stream(output_notes)\n",
    "midi_stream.write('midi', fp='v2_0_2.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 0\n",
    "output_notes = []\n",
    "\n",
    "# create note and chord objects based on the values generated by the model\n",
    "for pattern in prediction_output:\n",
    "    \n",
    "    note = patt\n",
    "    \n",
    "    # pattern is a chord\n",
    "    if ('.' in pattern) or pattern.isdigit():\n",
    "        notes_in_chord = pattern.split('.')\n",
    "        notes = []\n",
    "        for current_note in notes_in_chord:\n",
    "            new_note = note.Note(int(current_note))\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            notes.append(new_note)\n",
    "        new_chord = chord.Chord(notes)\n",
    "        new_chord.offset = offset\n",
    "        output_notes.append(new_chord)\n",
    "        \n",
    "    elif pattern == 'r':\n",
    "        new_note = note.Rest()\n",
    "        \n",
    "    # pattern is a note\n",
    "    else:\n",
    "        new_note = note.Note(pattern)\n",
    "        new_note.offset = offset\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        output_notes.append(new_note)\n",
    "        \n",
    "    # increase offset each iteration so that notes do not stack\n",
    "    offset += 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_output = []\n",
    "\n",
    "# generate 500 notes\n",
    "for note_index in range(100):\n",
    "    \n",
    "    # Reshape and scale sequence\n",
    "    prediction_input = np.reshape(pattern, (1,pattern.shape[0],pattern.shape[1]))\n",
    "    \n",
    "    # Predict next note\n",
    "    prediction = model.predict(prediction_input, verbose=0)\n",
    "    \n",
    "    \n",
    "    # Best Note:\n",
    "    note_draw = np.argmax(prediction[0])\n",
    "    duration_draw = np.argmax(prediction[1])\n",
    "    \n",
    "    result_draw = [note_draw,duration_draw]\n",
    "    \n",
    "    # Add note to our new sequence \n",
    "    note_result = int_to_note[note_draw]\n",
    "    duration_result = int_to_duration[duration_draw]\n",
    "    \n",
    "    result = [note_result,duration_result]\n",
    "    \n",
    "    new_pattern = prediction_input\n",
    "    new_pattern = np.append(new_pattern,result_draw)\n",
    "    new_pattern = np.delete(new_pattern,[0,1]).reshape(100,2)\n",
    "    \n",
    "    pattern = new_pattern\n",
    "    \n",
    "    \n",
    "    prediction_output.append(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th'],\n",
       " ['0', '16th']]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(prediction.flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 0\n",
    "output_notes = []\n",
    "\n",
    "# create note and chord objects based on the values generated by the model\n",
    "for pattern in prediction_output:\n",
    "    \n",
    "    # pattern is a chord\n",
    "    if ('.' in pattern) or pattern.isdigit():\n",
    "        notes_in_chord = pattern.split('.')\n",
    "        notes = []\n",
    "        for current_note in notes_in_chord:\n",
    "            new_note = note.Note(int(current_note))\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            notes.append(new_note)\n",
    "        new_chord = chord.Chord(notes)\n",
    "        new_chord.offset = offset\n",
    "        output_notes.append(new_chord)\n",
    "        \n",
    "    elif pattern == 'r':\n",
    "        new_note = note.Rest()\n",
    "        \n",
    "    # pattern is a note\n",
    "    else:\n",
    "        new_note = note.Note(pattern)\n",
    "        new_note.offset = offset\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        output_notes.append(new_note)\n",
    "        \n",
    "    # increase offset each iteration so that notes do not stack\n",
    "    offset += 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_stream = stream.Stream(output_notes)\n",
    "midi_stream.write('midi', fp='new_test_garbage_100.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network_input[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
